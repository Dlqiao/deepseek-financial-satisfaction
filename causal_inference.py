"""
å› æœæ¨æ–­æ¨¡å—ï¼šPSMã€DIDç­‰å› æœåˆ†ææ–¹æ³•å®ç°
"""

import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import NearestNeighbors
from sklearn.preprocessing import StandardScaler
import statsmodels.api as sm
from statsmodels.formula.api import ols
import logging
from typing import Dict, List, Tuple, Optional, Union
import warnings
warnings.filterwarnings('ignore')

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class PropensityScoreMatcher:
    """
    å€¾å‘æ€§è¯„åˆ†åŒ¹é…(PSM)å®ç°
    """
    
    def __init__(self, caliper: float = 0.2, ratio: int = 1, replace: bool = False):
        """
        åˆå§‹åŒ–PSMåŒ¹é…å™¨
        
        Args:
            caliper: åŒ¹é…å¡å°ºï¼Œä»¥å€¾å‘æ€§è¯„åˆ†æ ‡å‡†å·®çš„å€æ•°è¡¨ç¤º
            ratio: åŒ¹é…æ¯”ä¾‹ï¼ˆå¯¹ç…§ç»„:å¤„ç†ç»„ï¼‰
            replace: æ˜¯å¦å…è®¸æ”¾å›åŒ¹é…
        """
        self.caliper = caliper
        self.ratio = ratio
        self.replace = replace
        self.ps_model = None
        self.scaler = StandardScaler()
        self.matched_pairs = None
        self.balance_check = None
        
    def estimate_propensity_scores(self, 
                                   df: pd.DataFrame,
                                   treatment_col: str,
                                   feature_cols: List[str]) -> np.ndarray:
        """
        ä¼°è®¡å€¾å‘æ€§è¯„åˆ†
        
        Args:
            df: åŒ…å«å¤„ç†ç»„æ ‡è¯†å’Œç‰¹å¾çš„DataFrame
            treatment_col: å¤„ç†ç»„æ ‡è¯†åˆ—åï¼ˆ1=å¤„ç†ç»„ï¼Œ0=å¯¹ç…§ç»„ï¼‰
            feature_cols: ç”¨äºåŒ¹é…çš„ç‰¹å¾åˆ—ååˆ—è¡¨
            
        Returns:
            å€¾å‘æ€§è¯„åˆ†æ•°ç»„
        """
        logger.info("Estimating propensity scores...")
        
        X = df[feature_cols].copy()
        y = df[treatment_col].copy()
        
        # å¤„ç†ç¼ºå¤±å€¼
        X = X.fillna(X.mean())
        
        # æ ‡å‡†åŒ–ç‰¹å¾
        X_scaled = self.scaler.fit_transform(X)
        
        # è®­ç»ƒé€»è¾‘å›å½’æ¨¡å‹
        self.ps_model = LogisticRegression(random_state=42, max_iter=1000)
        self.ps_model.fit(X_scaled, y)
        
        # é¢„æµ‹å€¾å‘æ€§è¯„åˆ†
        propensity_scores = self.ps_model.predict_proba(X_scaled)[:, 1]
        
        logger.info(f"Propensity scores estimated, range: [{propensity_scores.min():.3f}, {propensity_scores.max():.3f}]")
        
        return propensity_scores
    
    def match(self, 
              df: pd.DataFrame,
              treatment_col: str,
              feature_cols: List[str],
              propensity_scores: Optional[np.ndarray] = None) -> pd.DataFrame:
        """
        æ‰§è¡Œå€¾å‘æ€§è¯„åˆ†åŒ¹é…
        
        Args:
            df: åŸå§‹æ•°æ®
            treatment_col: å¤„ç†ç»„æ ‡è¯†åˆ—
            feature_cols: ç‰¹å¾åˆ—
            propensity_scores: é¢„è®¡ç®—çš„å€¾å‘æ€§è¯„åˆ†ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            åŒ¹é…åçš„DataFrame
        """
        logger.info("Performing propensity score matching...")
        
        # åˆ†ç¦»å¤„ç†ç»„å’Œå¯¹ç…§ç»„
        treated = df[df[treatment_col] == 1].copy()
        control = df[df[treatment_col] == 0].copy()
        
        logger.info(f"Treated group size: {len(treated)}, Control group size: {len(control)}")
        
        # è®¡ç®—æˆ–ä½¿ç”¨å€¾å‘æ€§è¯„åˆ†
        if propensity_scores is None:
            ps = self.estimate_propensity_scores(df, treatment_col, feature_cols)
            treated['ps'] = ps[df[treatment_col] == 1]
            control['ps'] = ps[df[treatment_col] == 0]
        else:
            treated['ps'] = propensity_scores[df[treatment_col] == 1]
            control['ps'] = propensity_scores[df[treatment_col] == 0]
        
        # æ ‡å‡†åŒ–å€¾å‘æ€§è¯„åˆ†
        ps_scaler = StandardScaler()
        treated['ps_std'] = ps_scaler.fit_transform(treated[['ps']])
        control['ps_std'] = ps_scaler.transform(control[['ps']])
        
        # è®¡ç®—å¡å°ºé˜ˆå€¼
        ps_std = np.concatenate([treated['ps_std'].values, control['ps_std'].values])
        caliper_value = self.caliper * ps_std.std()
        
        # ä½¿ç”¨KNNè¿›è¡ŒåŒ¹é…
        knn = NearestNeighbors(n_neighbors=self.ratio, metric='euclidean')
        knn.fit(control[['ps_std']].values)
        
        distances, indices = knn.kneighbors(treated[['ps_std']].values)
        
        # åº”ç”¨å¡å°ºé™åˆ¶
        valid_matches = distances <= caliper_value
        
        # æ„å»ºåŒ¹é…ç»“æœ
        matched_pairs = []
        used_controls = set()
        
        for i, (treated_idx, control_indices) in enumerate(zip(treated.index, indices)):
            for j, control_idx in enumerate(control_indices):
                if valid_matches[i, j]:
                    if not self.replace and control_idx in used_controls:
                        continue
                    
                    matched_pairs.append({
                        'treated_id': treated_idx,
                        'control_id': control_idx,
                        'distance': distances[i, j],
                        'treated_ps': treated.loc[treated_idx, 'ps'],
                        'control_ps': control.loc[control_idx, 'ps']
                    })
                    
                    if not self.replace:
                        used_controls.add(control_idx)
                    
                    break  # åªå–æœ€è¿‘çš„ä¸€ä¸ªåŒ¹é…
        
        self.matched_pairs = pd.DataFrame(matched_pairs)
        
        logger.info(f"Matched {len(self.matched_pairs)} pairs")
        
        # æ„å»ºåŒ¹é…åçš„æ•°æ®é›†
        matched_treated = df.loc[self.matched_pairs['treated_id']].copy()
        matched_control = df.loc[self.matched_pairs['control_id']].copy()
        
        matched_treated['matched_id'] = range(len(matched_treated))
        matched_control['matched_id'] = range(len(matched_control))
        
        matched_df = pd.concat([matched_treated, matched_control], axis=0)
        
        return matched_df
    
    def check_balance(self, 
                      df: pd.DataFrame,
                      treatment_col: str,
                      feature_cols: List[str],
                      matched_df: Optional[pd.DataFrame] = None) -> pd.DataFrame:
        """
        æ£€æŸ¥åŒ¹é…åçš„å¹³è¡¡æ€§
        
        Args:
            df: åŸå§‹æ•°æ®
            treatment_col: å¤„ç†ç»„æ ‡è¯†åˆ—
            feature_cols: ç‰¹å¾åˆ—
            matched_df: åŒ¹é…åçš„æ•°æ®ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            å¹³è¡¡æ€§æ£€éªŒç»“æœ
        """
        logger.info("Checking balance...")
        
        if matched_df is None and self.matched_pairs is not None:
            matched_treated = df.loc[self.matched_pairs['treated_id']]
            matched_control = df.loc[self.matched_pairs['control_id']]
            matched_df = pd.concat([matched_treated, matched_control], axis=0)
        
        balance_results = []
        
        for feature in feature_cols:
            # åŒ¹é…å‰
            before_treated = df[df[treatment_col] == 1][feature].mean()
            before_control = df[df[treatment_col] == 0][feature].mean()
            before_std = df[feature].std()
            before_smd = (before_treated - before_control) / before_std if before_std > 0 else 0
            
            # åŒ¹é…å
            after_treated = matched_df[matched_df[treatment_col] == 1][feature].mean()
            after_control = matched_df[matched_df[treatment_col] == 0][feature].mean()
            after_std = matched_df[feature].std()
            after_smd = (after_treated - after_control) / after_std if after_std > 0 else 0
            
            # æ–¹å·®æ¯”
            before_var_ratio = (df[df[treatment_col] == 1][feature].var() / 
                               df[df[treatment_col] == 0][feature].var())
            after_var_ratio = (matched_df[matched_df[treatment_col] == 1][feature].var() / 
                              matched_df[matched_df[treatment_col] == 0][feature].var())
            
            balance_results.append({
                'feature': feature,
                'before_treated_mean': before_treated,
                'before_control_mean': before_control,
                'before_smd': abs(before_smd),
                'after_treated_mean': after_treated,
                'after_control_mean': after_control,
                'after_smd': abs(after_smd),
                'smd_reduction': (abs(before_smd) - abs(after_smd)) / abs(before_smd) if before_smd != 0 else 0,
                'before_var_ratio': before_var_ratio,
                'after_var_ratio': after_var_ratio,
                'is_balanced': abs(after_smd) < 0.1
            })
        
        self.balance_check = pd.DataFrame(balance_results)
        
        # ç»Ÿè®¡å¹³è¡¡æ€§
        n_balanced = self.balance_check['is_balanced'].sum()
        logger.info(f"Balance check: {n_balanced}/{len(feature_cols)} features balanced (SMD < 0.1)")
        
        return self.balance_check
    
    def estimate_ate(self, 
                    df: pd.DataFrame,
                    outcome_col: str,
                    treatment_col: str,
                    matched_df: Optional[pd.DataFrame] = None) -> Dict:
        """
        ä¼°è®¡å¹³å‡å¤„ç†æ•ˆåº”(ATE)
        
        Args:
            df: åŸå§‹æ•°æ®
            outcome_col: ç»“æœå˜é‡åˆ—å
            treatment_col: å¤„ç†ç»„æ ‡è¯†åˆ—
            matched_df: åŒ¹é…åçš„æ•°æ®ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            ATEä¼°è®¡ç»“æœ
        """
        logger.info("Estimating Average Treatment Effect (ATE)...")
        
        if matched_df is None and self.matched_pairs is not None:
            matched_treated = df.loc[self.matched_pairs['treated_id']]
            matched_control = df.loc[self.matched_pairs['control_id']]
            matched_df = pd.concat([matched_treated, matched_control], axis=0)
        
        # è®¡ç®—ATE
        treated_outcome = matched_df[matched_df[treatment_col] == 1][outcome_col].mean()
        control_outcome = matched_df[matched_df[treatment_col] == 0][outcome_col].mean()
        ate = treated_outcome - control_outcome
        
        # è®¡ç®—æ ‡å‡†è¯¯ï¼ˆä½¿ç”¨é…å¯¹tæ£€éªŒï¼‰
        if 'matched_id' in matched_df.columns:
            # å¦‚æœæœ‰åŒ¹é…IDï¼Œä½¿ç”¨é…å¯¹tæ£€éªŒ
            paired_data = matched_df.pivot(index='matched_id', columns=treatment_col, values=outcome_col)
            paired_data.columns = ['control', 'treated']
            paired_data = paired_data.dropna()
            
            from scipy import stats
            t_stat, p_value = stats.ttest_rel(paired_data['treated'], paired_data['control'])
            se = paired_data['treated'].std() / np.sqrt(len(paired_data))
        else:
            # å¦åˆ™ä½¿ç”¨ç‹¬ç«‹æ ·æœ¬tæ£€éªŒ
            from scipy import stats
            t_stat, p_value = stats.ttest_ind(
                matched_df[matched_df[treatment_col] == 1][outcome_col],
                matched_df[matched_df[treatment_col] == 0][outcome_col]
            )
            se = matched_df[outcome_col].std() / np.sqrt(len(matched_df))
        
        # è®¡ç®—ç½®ä¿¡åŒºé—´
        ci_lower = ate - 1.96 * se
        ci_upper = ate + 1.96 * se
        
        result = {
            'ate': ate,
            'treated_mean': treated_outcome,
            'control_mean': control_outcome,
            'se': se,
            't_stat': t_stat,
            'p_value': p_value,
            'ci_95': (ci_lower, ci_upper),
            'is_significant': p_value < 0.05,
            'sample_size': len(matched_df) // 2
        }
        
        logger.info(f"ATE = {ate:.4f}, p-value = {p_value:.4f}, significant: {result['is_significant']}")
        
        return result
    
    def estimate_att(self,
                    df: pd.DataFrame,
                    outcome_col: str,
                    treatment_col: str,
                    matched_df: Optional[pd.DataFrame] = None) -> Dict:
        """
        ä¼°è®¡å¤„ç†ç»„å¹³å‡å¤„ç†æ•ˆåº”(ATT)
        
        Args:
            df: åŸå§‹æ•°æ®
            outcome_col: ç»“æœå˜é‡åˆ—å
            treatment_col: å¤„ç†ç»„æ ‡è¯†åˆ—
            matched_df: åŒ¹é…åçš„æ•°æ®ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            ATTä¼°è®¡ç»“æœ
        """
        logger.info("Estimating Average Treatment Effect on Treated (ATT)...")
        
        if matched_df is None and self.matched_pairs is not None:
            matched_treated = df.loc[self.matched_pairs['treated_id']]
            matched_control = df.loc[self.matched_pairs['control_id']]
            matched_df = pd.concat([matched_treated, matched_control], axis=0)
        
        # ATTå°±æ˜¯åŒ¹é…åå¤„ç†ç»„å’Œå¯¹ç…§ç»„çš„å‡å€¼å·®
        treated_outcome = matched_df[matched_df[treatment_col] == 1][outcome_col].mean()
        control_outcome = matched_df[matched_df[treatment_col] == 0][outcome_col].mean()
        att = treated_outcome - control_outcome
        
        # è®¡ç®—æ ‡å‡†è¯¯
        from scipy import stats
        t_stat, p_value = stats.ttest_ind(
            matched_df[matched_df[treatment_col] == 1][outcome_col],
            matched_df[matched_df[treatment_col] == 0][outcome_col]
        )
        se = matched_df[outcome_col].std() / np.sqrt(len(matched_df))
        
        ci_lower = att - 1.96 * se
        ci_upper = att + 1.96 * se
        
        result = {
            'att': att,
            'treated_mean': treated_outcome,
            'control_mean': control_outcome,
            'se': se,
            't_stat': t_stat,
            'p_value': p_value,
            'ci_95': (ci_lower, ci_upper),
            'is_significant': p_value < 0.05,
            'sample_size': len(matched_df) // 2
        }
        
        logger.info(f"ATT = {att:.4f}, p-value = {p_value:.4f}, significant: {result['is_significant']}")
        
        return result


class DifferenceInDifferences:
    """
    åŒé‡å·®åˆ†(DID)æ¨¡å‹å®ç°
    """
    
    def __init__(self):
        self.model = None
        self.results = None
        
    def fit(self,
            df: pd.DataFrame,
            outcome_col: str,
            treatment_col: str,
            time_col: str,
            covariates: Optional[List[str]] = None) -> Dict:
        """
        æ‹ŸåˆDIDæ¨¡å‹
        
        Args:
            df: é¢æ¿æ•°æ®
            outcome_col: ç»“æœå˜é‡
            treatment_col: å¤„ç†ç»„æ ‡è¯†ï¼ˆ1=å¤„ç†ç»„ï¼Œ0=å¯¹ç…§ç»„ï¼‰
            time_col: æ—¶é—´æ ‡è¯†ï¼ˆ1=å¤„ç†åï¼Œ0=å¤„ç†å‰ï¼‰
            covariates: åå˜é‡åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            DIDä¼°è®¡ç»“æœ
        """
        logger.info("Fitting Difference-in-Differences model...")
        
        # æ„å»ºäº¤äº’é¡¹
        df = df.copy()
        df['treatment_time'] = df[treatment_col] * df[time_col]
        
        # æ„å»ºå…¬å¼
        formula = f"{outcome_col} ~ {treatment_col} + {time_col} + treatment_time"
        
        if covariates:
            formula += " + " + " + ".join(covariates)
        
        # æ‹ŸåˆOLSæ¨¡å‹
        self.model = ols(formula, data=df).fit()
        
        # æå–ç»“æœ
        self.results = {
            'did_estimator': self.model.params['treatment_time'],
            'p_value': self.model.pvalues['treatment_time'],
            'conf_int': self.model.conf_int().loc['treatment_time'].tolist(),
            'r_squared': self.model.rsquared,
            'adj_r_squared': self.model.rsquared_adj,
            'f_statistic': self.model.fvalue,
            'f_pvalue': self.model.f_pvalue,
            'sample_size': len(df)
        }
        
        # è®¡ç®—å„ç»„çš„å‡å€¼
        means = df.groupby([treatment_col, time_col])[outcome_col].mean().unstack()
        
        self.results.update({
            'control_before': means.loc[0, 0] if 0 in means.index and 0 in means.columns else None,
            'control_after': means.loc[0, 1] if 0 in means.index and 1 in means.columns else None,
            'treatment_before': means.loc[1, 0] if 1 in means.index and 0 in means.columns else None,
            'treatment_after': means.loc[1, 1] if 1 in means.index and 1 in means.columns else None
        })
        
        # è®¡ç®—å¹³è¡Œè¶‹åŠ¿æ£€éªŒï¼ˆå¦‚æœæœ‰å¤šä¸ªæ—¶é—´ç‚¹ï¼‰
        self.results['is_significant'] = self.results['p_value'] < 0.05
        
        logger.info(f"DID estimator = {self.results['did_estimator']:.4f}, p-value = {self.results['p_value']:.4f}")
        
        return self.results
    
    def parallel_trends_test(self,
                            df: pd.DataFrame,
                            outcome_col: str,
                            treatment_col: str,
                            time_col: str,
                            pre_periods: List) -> Dict:
        """
        å¹³è¡Œè¶‹åŠ¿å‡è®¾æ£€éªŒ
        
        Args:
            df: é¢æ¿æ•°æ®
            outcome_col: ç»“æœå˜é‡
            treatment_col: å¤„ç†ç»„æ ‡è¯†
            time_col: æ—¶é—´åˆ—ï¼ˆå¤šä¸ªæ—¶é—´ç‚¹ï¼‰
            pre_periods: å¤„ç†å‰çš„æ—¶é—´ç‚¹åˆ—è¡¨
            
        Returns:
            å¹³è¡Œè¶‹åŠ¿æ£€éªŒç»“æœ
        """
        logger.info("Testing parallel trends assumption...")
        
        # åªä½¿ç”¨å¤„ç†å‰æ•°æ®
        pre_data = df[df[time_col].isin(pre_periods)].copy()
        
        # æ„å»ºæ—¶é—´è¶‹åŠ¿ä¸å¤„ç†ç»„çš„äº¤äº’é¡¹
        pre_data['time_trend'] = pre_data[time_col].astype(float)
        pre_data['treatment_trend'] = pre_data[treatment_col] * pre_data['time_trend']
        
        # æ‹Ÿåˆæ¨¡å‹
        formula = f"{outcome_col} ~ {treatment_col} + time_trend + treatment_trend"
        model = ols(formula, data=pre_data).fit()
        
        # æ£€éªŒäº¤äº’é¡¹æ˜¯å¦æ˜¾è‘—ï¼ˆå¦‚æœæ˜¾è‘—ï¼Œåˆ™å¹³è¡Œè¶‹åŠ¿å‡è®¾å¯èƒ½ä¸æˆç«‹ï¼‰
        p_value = model.pvalues['treatment_trend']
        coef = model.params['treatment_trend']
        
        result = {
            'trend_difference': coef,
            'p_value': p_value,
            'parallel_trends_assumption_holds': p_value > 0.05,
            'model_summary': model.summary().as_text()
        }
        
        logger.info(f"Parallel trends test p-value: {p_value:.4f}, holds: {result['parallel_trends_assumption_holds']}")
        
        return result
    
    def placebo_test(self,
                    df: pd.DataFrame,
                    outcome_col: str,
                    treatment_col: str,
                    time_col: str,
                    placebo_time: str) -> Dict:
        """
        å®‰æ…°å‰‚æ£€éªŒï¼ˆå‡è®¾å¤„ç†å‘ç”Ÿåœ¨æ›´æ—©çš„æ—¶é—´ï¼‰
        
        Args:
            df: é¢æ¿æ•°æ®
            outcome_col: ç»“æœå˜é‡
            treatment_col: å¤„ç†ç»„æ ‡è¯†
            time_col: æ—¶é—´åˆ—
            placebo_time: å®‰æ…°å‰‚å¤„ç†æ—¶é—´ç‚¹
            
        Returns:
            å®‰æ…°å‰‚æ£€éªŒç»“æœ
        """
        logger.info(f"Running placebo test with treatment at {placebo_time}...")
        
        # åˆ›å»ºå®‰æ…°å‰‚æ—¶é—´æ ‡è¯†
        df = df.copy()
        df['placebo_time'] = (df[time_col] >= placebo_time).astype(int)
        df['placebo_interaction'] = df[treatment_col] * df['placebo_time']
        
        # åªä½¿ç”¨å®é™…å¤„ç†å‰çš„æ•°æ®
        actual_treatment_time = df[time_col].max()  # å‡è®¾æœ€åä¸€ä¸ªæ˜¯å®é™…å¤„ç†æ—¶é—´
        pre_data = df[df[time_col] < actual_treatment_time].copy()
        
        # æ‹Ÿåˆæ¨¡å‹
        formula = f"{outcome_col} ~ {treatment_col} + placebo_time + placebo_interaction"
        model = ols(formula, data=pre_data).fit()
        
        # å¦‚æœå®‰æ…°å‰‚æ•ˆåº”æ˜¾è‘—ï¼Œè¯´æ˜å­˜åœ¨å…¶ä»–æ··æ‚å› ç´ 
        placebo_effect = model.params['placebo_interaction']
        p_value = model.pvalues['placebo_interaction']
        
        result = {
            'placebo_effect': placebo_effect,
            'p_value': p_value,
            'is_robust': p_value > 0.05,  # å®‰æ…°å‰‚æ•ˆåº”ä¸æ˜¾è‘—ï¼Œè¯´æ˜ç»“æœç¨³å¥
            'model_summary': model.summary().as_text()
        }
        
        logger.info(f"Placebo effect p-value: {p_value:.4f}, robust: {result['is_robust']}")
        
        return result


class CausalInferencePipeline:
    """
    å› æœæ¨æ–­å®Œæ•´ç®¡é“
    """
    
    def __init__(self):
        self.psm = PropensityScoreMatcher()
        self.did = DifferenceInDifferences()
        self.results = {}
        
    def run_analysis(self,
                    df: pd.DataFrame,
                    treatment_col: str,
                    outcome_col: str,
                    feature_cols: List[str],
                    time_col: Optional[str] = None,
                    panel_data: bool = False) -> Dict:
        """
        è¿è¡Œå®Œæ•´çš„å› æœæ¨æ–­åˆ†æ
        
        Args:
            df: æ•°æ®
            treatment_col: å¤„ç†ç»„æ ‡è¯†
            outcome_col: ç»“æœå˜é‡
            feature_cols: ç‰¹å¾åˆ—ï¼ˆç”¨äºPSMï¼‰
            time_col: æ—¶é—´åˆ—ï¼ˆç”¨äºDIDï¼‰
            panel_data: æ˜¯å¦ä¸ºé¢æ¿æ•°æ®
            
        Returns:
            å®Œæ•´çš„åˆ†æç»“æœ
        """
        logger.info("Running complete causal inference pipeline...")
        
        results = {}
        
        # 1. PSMåˆ†æ
        logger.info("\n=== Step 1: Propensity Score Matching ===")
        
        # ä¼°è®¡å€¾å‘æ€§è¯„åˆ†
        ps = self.psm.estimate_propensity_scores(df, treatment_col, feature_cols)
        
        # æ‰§è¡ŒåŒ¹é…
        matched_df = self.psm.match(df, treatment_col, feature_cols, ps)
        
        # å¹³è¡¡æ€§æ£€éªŒ
        balance = self.psm.check_balance(df, treatment_col, feature_cols, matched_df)
        results['balance_check'] = balance.to_dict('records')
        
        # ä¼°è®¡ATE
        ate = self.psm.estimate_ate(df, outcome_col, treatment_col, matched_df)
        results['psm_ate'] = ate
        
        # 2. DIDåˆ†æï¼ˆå¦‚æœæ˜¯é¢æ¿æ•°æ®ï¼‰
        if panel_data and time_col is not None:
            logger.info("\n=== Step 2: Difference-in-Differences ===")
            
            did_results = self.did.fit(df, outcome_col, treatment_col, time_col)
            results['did'] = did_results
            
            # å¹³è¡Œè¶‹åŠ¿æ£€éªŒ
            pre_periods = sorted(df[time_col].unique())[:-1]  # å‡è®¾æœ€åä¸€ä¸ªæ—¶é—´æ˜¯å¤„ç†å
            parallel_test = self.did.parallel_trends_test(
                df, outcome_col, treatment_col, time_col, pre_periods
            )
            results['parallel_trends_test'] = parallel_test
            
            # å®‰æ…°å‰‚æ£€éªŒ
            if len(pre_periods) > 1:
                placebo_time = pre_periods[-1]  # ç”¨å¤„ç†å‰æœ€åä¸€ä¸ªæ—¶é—´ç‚¹åšå®‰æ…°å‰‚
                placebo_test = self.did.placebo_test(
                    df, outcome_col, treatment_col, time_col, placebo_time
                )
                results['placebo_test'] = placebo_test
        
        # 3. æ€»ç»“
        results['summary'] = self._generate_summary(results)
        
        self.results = results
        return results
    
    def _generate_summary(self, results: Dict) -> str:
        """ç”Ÿæˆåˆ†ææ€»ç»“"""
        summary = []
        summary.append("=" * 50)
        summary.append("CAUSAL INFERENCE ANALYSIS SUMMARY")
        summary.append("=" * 50)
        
        if 'psm_ate' in results:
            ate = results['psm_ate']
            summary.append("\nğŸ“Š Propensity Score Matching Results:")
            summary.append(f"  - ATE: {ate['ate']:.4f}")
            summary.append(f"  - 95% CI: [{ate['ci_95'][0]:.4f}, {ate['ci_95'][1]:.4f}]")
            summary.append(f"  - p-value: {ate['p_value']:.4f}")
            summary.append(f"  - Significant: {ate['is_significant']}")
        
        if 'did' in results:
            did = results['did']
            summary.append("\nğŸ“ˆ Difference-in-Differences Results:")
            summary.append(f"  - DID Estimator: {did['did_estimator']:.4f}")
            summary.append(f"  - p-value: {did['p_value']:.4f}")
            summary.append(f"  - R-squared: {did['r_squared']:.4f}")
            summary.append(f"  - Significant: {did['is_significant']}")
        
        if 'parallel_trends_test' in results:
            pt = results['parallel_trends_test']
            summary.append(f"\nğŸ”„ Parallel Trends Test:")
            summary.append(f"  - Holds: {pt['parallel_trends_assumption_holds']}")
        
        summary.append("\n" + "=" * 50)
        
        return "\n".join(summary)


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
    np.random.seed(42)
    n = 1000
    
    # ç‰¹å¾
    df = pd.DataFrame({
        'user_id': range(n),
        'age': np.random.normal(35, 10, n),
        'investment_exp': np.random.exponential(5, n),
        'risk_score': np.random.uniform(0, 10, n),
        'query_frequency': np.random.poisson(10, n),
        'treatment': np.random.binomial(1, 0.3, n),  # å¤„ç†ç»„
        'satisfaction': np.random.normal(3.5, 1, n),  # ç»“æœå˜é‡
        'time': np.random.choice([0, 1], n)  # æ—¶é—´ï¼ˆ0=å‰ï¼Œ1=åï¼‰
    })
    
    # æ·»åŠ å¤„ç†æ•ˆåº”ï¼ˆå‡è®¾å¤„ç†ç»„æ»¡æ„åº¦+0.5ï¼‰
    df.loc[df['treatment'] == 1, 'satisfaction'] += 0.5
    
    # ç‰¹å¾åˆ—
    feature_cols = ['age', 'investment_exp', 'risk_score', 'query_frequency']
    
    # è¿è¡Œå› æœæ¨æ–­
    pipeline = CausalInferencePipeline()
    results = pipeline.run_analysis(
        df=df,
        treatment_col='treatment',
        outcome_col='satisfaction',
        feature_cols=feature_cols,
        time_col='time',
        panel_data=True
    )
    
    # æ‰“å°ç»“æœ
    print(results['summary'])
    
    # æŸ¥çœ‹å¹³è¡¡æ€§æ£€éªŒ
    if 'balance_check' in results:
        balance_df = pd.DataFrame(results['balance_check'])
        print("\nğŸ“Š Balance Check (first 5 features):")
        print(balance_df[['feature', 'before_smd', 'after_smd', 'is_balanced']].head())
        