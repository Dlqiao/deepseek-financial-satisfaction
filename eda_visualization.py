#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DeepSeeké‡‘èå‚åŸŸè‚¡ç¥¨åˆ†ææ»¡æ„åº¦é¡¹ç›® - æ¢ç´¢æ€§æ•°æ®åˆ†æ(EDA)
å®Œå…¨ä½¿ç”¨Pythonè„šæœ¬ï¼Œä¸éœ€è¦Jupyter
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['figure.figsize'] = (12, 6)
sns.set_style('whitegrid')


class FinancialEDA:
    """
    é‡‘èæ»¡æ„åº¦æ•°æ®åˆ†æç±»
    åŒ…å«æ•°æ®ç”Ÿæˆã€å¯è§†åŒ–ã€åˆ†ææŠ¥å‘Šç­‰åŠŸèƒ½
    """
    
    def __init__(self, n_samples=10000, random_seed=42):
        """
        åˆå§‹åŒ–EDAåˆ†æå™¨
        
        Args:
            n_samples: æ ·æœ¬æ•°é‡
            random_seed: éšæœºç§å­
        """
        self.n_samples = n_samples
        np.random.seed(random_seed)
        self.df = None
        self.stocks_df = None
        self.users_df = None
        
    def generate_data(self):
        """ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ï¼ˆå®é™…é¡¹ç›®ä¸­åº”ä»æ•°æ®åº“è¯»å–ï¼‰"""
        print("ğŸ“Š æ­£åœ¨ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®...")
        
        # 1. è‚¡ç¥¨æ•°æ®
        self.stocks_df = pd.DataFrame({
            'stock_code': ['600519.SH', '000858.SZ', '601318.SH', '600036.SH', '000002.SZ',
                          '002415.SZ', '300750.SZ', '000333.SZ', '002594.SZ', '688981.SH',
                          '300059.SZ', '600030.SH', '000001.SZ', '002714.SZ', '300760.SZ'],
            'stock_name': ['è´µå·èŒ…å°', 'äº”ç²®æ¶²', 'ä¸­å›½å¹³å®‰', 'æ‹›å•†é“¶è¡Œ', 'ä¸‡ç§‘A',
                          'æµ·åº·å¨è§†', 'å®å¾·æ—¶ä»£', 'ç¾çš„é›†å›¢', 'æ¯”äºšè¿ª', 'ä¸­èŠ¯å›½é™…',
                          'ä¸œæ–¹è´¢å¯Œ', 'ä¸­ä¿¡è¯åˆ¸', 'å¹³å®‰é“¶è¡Œ', 'ç‰§åŸè‚¡ä»½', 'è¿ˆç‘åŒ»ç–—'],
            'industry': ['é£Ÿå“é¥®æ–™', 'é£Ÿå“é¥®æ–™', 'ä¿é™©', 'é“¶è¡Œ', 'æˆ¿åœ°äº§',
                        'è®¡ç®—æœº', 'ç”µåŠ›è®¾å¤‡', 'å®¶ç”µ', 'æ±½è½¦', 'ç”µå­',
                        'è¯åˆ¸', 'è¯åˆ¸', 'é“¶è¡Œ', 'å†œæ—ç‰§æ¸”', 'åŒ»è¯ç”Ÿç‰©'],
            'market_cap': [20000, 6000, 8000, 9000, 1500,
                          3500, 12000, 4500, 7000, 4000,
                          2500, 3000, 2000, 2500, 3800],
            'pe_ttm': [30, 25, 8, 6, 10, 25, 40, 15, 60, 50, 30, 15, 5, 20, 35]
        })
        
        # 2. ç”¨æˆ·æ•°æ®
        self.users_df = pd.DataFrame({
            'user_id': [f'user_{i}' for i in range(1, 1001)],
            'user_type': np.random.choice(['å…è´¹', 'ä»˜è´¹', 'ä¼ä¸š'], size=1000, p=[0.6, 0.3, 0.1]),
            'risk_profile': np.random.choice(['ä¿å®ˆ', 'ç¨³å¥', 'è¿›å–'], size=1000, p=[0.3, 0.5, 0.2]),
            'investment_exp': np.random.randint(0, 20, 1000),
            'registration_days': np.random.randint(1, 500, 1000)
        })
        
        # 3. æŸ¥è¯¢æ•°æ®
        queries = []
        query_types = ['åŸºæœ¬é¢åˆ†æ', 'æŠ€æœ¯åˆ†æ', 'è´¢æŠ¥è§£è¯»', 'è¡Œä¸šå¯¹æ¯”', 'æŠ•èµ„å»ºè®®', 'è‚¡ä»·æŸ¥è¯¢']
        experiment_groups = ['control', 'treatment_rag', 'treatment_prompt', 'treatment_combined']
        group_weights = [0.4, 0.2, 0.2, 0.2]
        
        for i in range(self.n_samples):
            user_id = f'user_{np.random.randint(1, 1001)}'
            n_stocks = np.random.choice([1, 2, 3], p=[0.7, 0.2, 0.1])
            selected_stocks = self.stocks_df.sample(n_stocks)
            
            hour = np.random.randint(0, 24)
            is_trading_hour = (9 <= hour <= 11) or (13 <= hour <= 15)
            
            queries.append({
                'query_id': i + 10000,
                'user_id': user_id,
                'query_time': pd.Timestamp('2025-02-01') + pd.Timedelta(hours=np.random.randint(0, 720)),
                'query_type': np.random.choice(query_types),
                'stock_codes': ','.join(selected_stocks['stock_code'].tolist()),
                'stock_names': ','.join(selected_stocks['stock_name'].tolist()),
                'industries': ','.join(selected_stocks['industry'].unique()),
                'avg_market_cap': selected_stocks['market_cap'].mean(),
                'min_market_cap': selected_stocks['market_cap'].min(),
                'max_market_cap': selected_stocks['market_cap'].max(),
                'n_stocks': n_stocks,
                'hour': hour,
                'is_trading_hour': is_trading_hour,
                'day_of_week': np.random.randint(0, 7),
                'experiment_group': np.random.choice(experiment_groups, p=group_weights),
                'query_length': np.random.randint(20, 200)
            })
        
        queries_df = pd.DataFrame(queries)
        
        # 4. åé¦ˆæ•°æ®
        feedback = []
        for _, query in queries_df.iterrows():
            # åŸºç¡€æ»¡æ„åº¦ï¼ˆå¤§ç›˜è‚¡æ»¡æ„åº¦é«˜ï¼Œå°ç›˜è‚¡æ»¡æ„åº¦ä½ï¼‰
            base_satisfaction = 0.5
            
            if query['avg_market_cap'] > 1000:
                base_satisfaction += 0.3
            elif query['avg_market_cap'] > 100:
                base_satisfaction += 0.1
            elif query['avg_market_cap'] > 10:
                base_satisfaction -= 0.1
            else:
                base_satisfaction -= 0.3
            
            # å®éªŒç»„å½±å“
            if query['experiment_group'] == 'treatment_rag':
                base_satisfaction += 0.15
            elif query['experiment_group'] == 'treatment_prompt':
                base_satisfaction += 0.1
            elif query['experiment_group'] == 'treatment_combined':
                base_satisfaction += 0.25
            
            # æŸ¥è¯¢ç±»å‹å½±å“
            if query['query_type'] in ['è´¢æŠ¥è§£è¯»', 'åŸºæœ¬é¢åˆ†æ']:
                base_satisfaction += 0.05
            
            prob = 1 / (1 + np.exp(-base_satisfaction))
            is_satisfied = np.random.random() < prob
            
            if is_satisfied:
                rating = np.random.randint(4, 6)
                nps = np.random.randint(7, 11)
            else:
                rating = np.random.randint(1, 4)
                nps = np.random.randint(0, 7)
            
            feedback.append({
                'query_id': query['query_id'],
                'rating': rating,
                'nps_score': nps,
                'is_satisfied': 1 if rating >= 4 else 0
            })
        
        feedback_df = pd.DataFrame(feedback)
        
        # 5. åˆå¹¶æ•°æ®
        self.df = queries_df.merge(feedback_df, on='query_id')
        self.df = self.df.merge(self.users_df, on='user_id')
        
        # æ·»åŠ å¸‚å€¼åˆ†ç±»
        def categorize_market_cap(cap):
            if cap > 1000:
                return 'å¤§ç›˜è‚¡ (>1000äº¿)'
            elif cap > 100:
                return 'ä¸­ç›˜è‚¡ (100-1000äº¿)'
            elif cap > 10:
                return 'å°ç›˜è‚¡ (10-100äº¿)'
            else:
                return 'å¾®ç›˜è‚¡ (<10äº¿)'
        
        self.df['market_cap_category'] = self.df['avg_market_cap'].apply(categorize_market_cap)
        self.df['hour'] = self.df['query_time'].dt.hour
        
        print(f"âœ… æ•°æ®ç”Ÿæˆå®Œæˆï¼š{len(self.df)} æ¡è®°å½•")
        print(f"   - ç”¨æˆ·æ•°: {self.df['user_id'].nunique()}")
        print(f"   - æ—¶é—´èŒƒå›´: {self.df['query_time'].min()} åˆ° {self.df['query_time'].max()}")
        
        return self.df
    
    def data_overview(self):
        """æ•°æ®æ¦‚è§ˆ"""
        print("\n" + "="*60)
        print("ğŸ“‹ æ•°æ®æ¦‚è§ˆ")
        print("="*60)
        
        print(f"æ€»è®°å½•æ•°: {len(self.df):,}")
        print(f"å”¯ä¸€ç”¨æˆ·æ•°: {self.df['user_id'].nunique():,}")
        print(f"æ—¶é—´èŒƒå›´: {self.df['query_time'].min()} åˆ° {self.df['query_time'].max()}")
        
        print("\næ ¸å¿ƒæŒ‡æ ‡ç»Ÿè®¡:")
        print(self.df[['rating', 'nps_score', 'is_satisfied']].describe())
        
        print("\nç¼ºå¤±å€¼æ£€æŸ¥:")
        missing = self.df.isnull().sum()
        print(missing[missing > 0] if any(missing > 0) else "æ— ç¼ºå¤±å€¼")
    
    def plot_satisfaction_distribution(self, save_path=None):
        """æ»¡æ„åº¦åˆ†å¸ƒå›¾"""
        fig, axes = plt.subplots(2, 2, figsize=(14, 10))
        
        # 1. è¯„åˆ†åˆ†å¸ƒ
        axes[0, 0].hist(self.df['rating'], bins=5, edgecolor='black', color='skyblue')
        axes[0, 0].set_xlabel('è¯„åˆ†')
        axes[0, 0].set_ylabel('é¢‘æ¬¡')
        axes[0, 0].set_title('ç”¨æˆ·è¯„åˆ†åˆ†å¸ƒ')
        
        # 2. NPSåˆ†å¸ƒ
        axes[0, 1].hist(self.df['nps_score'], bins=11, edgecolor='black', color='lightgreen')
        axes[0, 1].set_xlabel('NPSè¯„åˆ†')
        axes[0, 1].set_ylabel('é¢‘æ¬¡')
        axes[0, 1].set_title('NPSè¯„åˆ†åˆ†å¸ƒ')
        
        # 3. ç”¨æˆ·ç±»å‹åˆ†å¸ƒ
        user_type_counts = self.df['user_type'].value_counts()
        axes[1, 0].pie(user_type_counts.values, labels=user_type_counts.index, 
                       autopct='%1.1f%%', colors=['skyblue', 'lightgreen', 'lightcoral'])
        axes[1, 0].set_title('ç”¨æˆ·ç±»å‹åˆ†å¸ƒ')
        
        # 4. æŸ¥è¯¢ç±»å‹åˆ†å¸ƒ
        query_type_counts = self.df['query_type'].value_counts()
        axes[1, 1].barh(query_type_counts.index, query_type_counts.values, color='orange')
        axes[1, 1].set_xlabel('é¢‘æ¬¡')
        axes[1, 1].set_title('æŸ¥è¯¢ç±»å‹åˆ†å¸ƒ')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ… å›¾è¡¨å·²ä¿å­˜: {save_path}")
        
        plt.show()
    
    def analyze_hunger_phenomenon(self, save_path=None):
        """
        åˆ†æ"åƒä¸é¥±"ç°è±¡ï¼šå¸‚å€¼ä¸æ»¡æ„åº¦çš„å…³ç³»
        """
        print("\n" + "="*60)
        print("ğŸ½ï¸ éªŒè¯'åƒä¸é¥±'ç°è±¡ï¼šå¸‚å€¼ä¸æ»¡æ„åº¦çš„å…³ç³»")
        print("="*60)
        
        # æŒ‰å¸‚å€¼åˆ†ç±»ç»Ÿè®¡
        market_stats = self.df.groupby('market_cap_category').agg({
            'is_satisfied': ['mean', 'count'],
            'rating': 'mean',
            'nps_score': 'mean'
        }).round(3)
        market_stats.columns = ['æ»¡æ„åº¦', 'æ ·æœ¬é‡', 'å¹³å‡è¯„åˆ†', 'å¹³å‡NPS']
        market_stats = market_stats.reset_index()
        
        print("\nä¸åŒå¸‚å€¼è‚¡ç¥¨çš„æ»¡æ„åº¦å¯¹æ¯”:")
        print(market_stats.to_string(index=False))
        
        # å¯è§†åŒ–
        fig, axes = plt.subplots(1, 2, figsize=(15, 6))
        
        # æ»¡æ„åº¦æŸ±çŠ¶å›¾
        ax1 = axes[0]
        colors = ['green' if i == 0 else 'orange' if i == 1 else 'red' if i == 2 else 'darkred' 
                  for i in range(len(market_stats))]
        bars = ax1.bar(market_stats['market_cap_category'], market_stats['æ»¡æ„åº¦'], color=colors)
        ax1.set_xlabel('è‚¡ç¥¨å¸‚å€¼åˆ†ç±»')
        ax1.set_ylabel('æ»¡æ„åº¦')
        ax1.set_title('ä¸åŒå¸‚å€¼è‚¡ç¥¨çš„æ»¡æ„åº¦å¯¹æ¯”')
        ax1.set_ylim(0, 1)
        
        for bar, val in zip(bars, market_stats['æ»¡æ„åº¦']):
            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{val:.1%}', ha='center')
        
        # æ ·æœ¬é‡åˆ†å¸ƒ
        ax2 = axes[1]
        ax2.pie(market_stats['æ ·æœ¬é‡'], labels=market_stats['market_cap_category'],
                autopct='%1.1f%%', colors=colors)
        ax2.set_title('å„å¸‚å€¼åˆ†ç±»æ ·æœ¬é‡åˆ†å¸ƒ')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        
        plt.show()
        
        # è¡Œä¸šåˆ†æ
        print("\nå„è¡Œä¸šæ»¡æ„åº¦æ’åï¼ˆTOP 10ï¼‰:")
        industry_stats = self.df.groupby('industries').agg({
            'is_satisfied': 'mean',
            'query_id': 'count',
            'avg_market_cap': 'mean'
        }).round(3)
        industry_stats.columns = ['æ»¡æ„åº¦', 'æŸ¥è¯¢æ¬¡æ•°', 'å¹³å‡å¸‚å€¼']
        industry_stats = industry_stats.sort_values('æ»¡æ„åº¦', ascending=False).head(10)
        print(industry_stats)
        
        return market_stats
    
    def analyze_ab_test(self, save_path=None):
        """
        ABå®éªŒæ•ˆæœåˆ†æ
        """
        print("\n" + "="*60)
        print("ğŸ§ª ABå®éªŒæ•ˆæœåˆ†æ")
        print("="*60)
        
        # å®éªŒç»„ç»Ÿè®¡
        exp_stats = self.df.groupby('experiment_group').agg({
            'is_satisfied': ['mean', 'count'],
            'rating': 'mean',
            'nps_score': 'mean'
        }).round(3)
        exp_stats.columns = ['æ»¡æ„åº¦', 'æ ·æœ¬é‡', 'å¹³å‡è¯„åˆ†', 'å¹³å‡NPS']
        exp_stats = exp_stats.reset_index()
        
        # åˆ†ç»„åç§°æ˜ å°„
        group_names = {
            'control': 'å¯¹ç…§ç»„',
            'treatment_rag': 'å®éªŒç»„A (RAGå¢å¼º)',
            'treatment_prompt': 'å®éªŒç»„B (ç»“æ„åŒ–Prompt)',
            'treatment_combined': 'å®éªŒç»„C (RAG+Promptç»„åˆ)'
        }
        exp_stats['å®éªŒç»„'] = exp_stats['experiment_group'].map(group_names)
        
        print("\nå„å®éªŒç»„æˆæ•ˆå¯¹æ¯”:")
        print(exp_stats[['å®éªŒç»„', 'æ»¡æ„åº¦', 'å¹³å‡è¯„åˆ†', 'å¹³å‡NPS', 'æ ·æœ¬é‡']].to_string(index=False))
        
        # è®¡ç®—æå‡
        control_sat = exp_stats[exp_stats['experiment_group'] == 'control']['æ»¡æ„åº¦'].values[0]
        combined_sat = exp_stats[exp_stats['experiment_group'] == 'treatment_combined']['æ»¡æ„åº¦'].values[0]
        lift = (combined_sat - control_sat) / control_sat
        print(f"\nğŸ“ˆ å®éªŒç»„Cç›¸æ¯”å¯¹ç…§ç»„æ»¡æ„åº¦æå‡: {lift:.1%}")
        
        # å¯è§†åŒ–
        fig, axes = plt.subplots(1, 2, figsize=(15, 6))
        
        # æ»¡æ„åº¦å¯¹æ¯”
        ax1 = axes[0]
        bars1 = ax1.bar(exp_stats['å®éªŒç»„'], exp_stats['æ»¡æ„åº¦'])
        ax1.set_xlabel('å®éªŒç»„')
        ax1.set_ylabel('æ»¡æ„åº¦')
        ax1.set_title('å„å®éªŒç»„æ»¡æ„åº¦å¯¹æ¯”')
        ax1.set_ylim(0, 1)
        ax1.tick_params(axis='x', rotation=15)
        
        for bar, val in zip(bars1, exp_stats['æ»¡æ„åº¦']):
            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{val:.1%}', ha='center')
        
        # NPSå¯¹æ¯”
        ax2 = axes[1]
        bars2 = ax2.bar(exp_stats['å®éªŒç»„'], exp_stats['å¹³å‡NPS'])
        ax2.set_xlabel('å®éªŒç»„')
        ax2.set_ylabel('å¹³å‡NPS')
        ax2.set_title('å„å®éªŒç»„NPSå¯¹æ¯”')
        ax2.axhline(y=0, color='gray', linestyle='--', alpha=0.5)
        ax2.tick_params(axis='x', rotation=15)
        
        for bar, val in zip(bars2, exp_stats['å¹³å‡NPS']):
            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                    f'{val:.1f}', ha='center')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        
        plt.show()
        
        # å®éªŒç»„åœ¨ä¸åŒå¸‚å€¼è‚¡ç¥¨ä¸Šçš„è¡¨ç°
        exp_market = self.df.groupby(['experiment_group', 'market_cap_category'])['is_satisfied'].mean().unstack()
        
        plt.figure(figsize=(12, 6))
        exp_market.T.plot(kind='bar', ax=plt.gca())
        plt.xlabel('è‚¡ç¥¨å¸‚å€¼åˆ†ç±»')
        plt.ylabel('æ»¡æ„åº¦')
        plt.title('å„å®éªŒç»„åœ¨ä¸åŒå¸‚å€¼è‚¡ç¥¨ä¸Šçš„æ»¡æ„åº¦è¡¨ç°')
        plt.legend(title='å®éªŒç»„', labels=['å¯¹ç…§ç»„', 'RAGå¢å¼º', 'ç»“æ„åŒ–Prompt', 'RAG+Promptç»„åˆ'])
        plt.ylim(0, 1)
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.show()
        
        return exp_stats
    
    def analyze_user_behavior(self, save_path=None):
        """
        ç”¨æˆ·è¡Œä¸ºåˆ†æ
        """
        print("\n" + "="*60)
        print("ğŸ‘¥ ç”¨æˆ·è¡Œä¸ºåˆ†æ")
        print("="*60)
        
        # ç”¨æˆ·ç±»å‹åˆ†æ
        user_stats = self.df.groupby('user_type').agg({
            'is_satisfied': 'mean',
            'rating': 'mean',
            'nps_score': 'mean',
            'user_id': 'nunique'
        }).round(3)
        user_stats.columns = ['æ»¡æ„åº¦', 'å¹³å‡è¯„åˆ†', 'å¹³å‡NPS', 'ç”¨æˆ·æ•°']
        
        print("\nä¸åŒç”¨æˆ·ç±»å‹çš„æ»¡æ„åº¦:")
        print(user_stats)
        
        # æŸ¥è¯¢æ—¶é—´åˆ†æ
        hourly_stats = self.df.groupby('hour').agg({
            'is_satisfied': 'mean',
            'query_id': 'count'
        }).reset_index()
        
        fig, ax1 = plt.subplots(figsize=(14, 6))
        
        # æŸ±çŠ¶å›¾ï¼šæŸ¥è¯¢é‡
        bars = ax1.bar(hourly_stats['hour'], hourly_stats['query_id'], alpha=0.5, color='gray')
        ax1.set_xlabel('å°æ—¶')
        ax1.set_ylabel('æŸ¥è¯¢æ¬¡æ•°', color='gray')
        ax1.tick_params(axis='y', labelcolor='gray')
        
        # æŠ˜çº¿å›¾ï¼šæ»¡æ„åº¦
        ax2 = ax1.twinx()
        ax2.plot(hourly_stats['hour'], hourly_stats['is_satisfied'], 'r-', linewidth=2, marker='o')
        ax2.set_ylabel('æ»¡æ„åº¦', color='red')
        ax2.tick_params(axis='y', labelcolor='red')
        ax2.set_ylim(0, 1)
        
        # æ ‡è®°äº¤æ˜“æ—¶æ®µ
        ax1.axvspan(9, 11, alpha=0.2, color='green', label='äº¤æ˜“æ—¶æ®µ 9:00-11:30')
        ax1.axvspan(13, 15, alpha=0.2, color='green')
        
        plt.title('æŸ¥è¯¢æ—¶é—´åˆ†å¸ƒä¸æ»¡æ„åº¦å˜åŒ–')
        fig.legend(loc='upper right')
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        
        plt.show()
        
        return user_stats
    
    def correlation_analysis(self):
        """
        ç›¸å…³æ€§åˆ†æ
        """
        print("\n" + "="*60)
        print("ğŸ”— ç›¸å…³æ€§åˆ†æ")
        print("="*60)
        
        numeric_cols = ['rating', 'nps_score', 'is_satisfied', 'avg_market_cap', 
                       'n_stocks', 'hour', 'query_length', 'investment_exp', 
                       'registration_days']
        
        corr_matrix = self.df[numeric_cols].corr()
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(corr_matrix, annot=True, cmap='RdBu_r', center=0, 
                    square=True, linewidths=1, cbar_kws={'shrink': 0.8})
        plt.title('ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾')
        plt.tight_layout()
        plt.show()
        
        # æ‰¾å‡ºä¸æ»¡æ„åº¦æœ€ç›¸å…³çš„ç‰¹å¾
        sat_corr = corr_matrix['is_satisfied'].drop('is_satisfied').sort_values(ascending=False)
        print("\nä¸æ»¡æ„åº¦æœ€ç›¸å…³çš„ç‰¹å¾:")
        for feat, corr in sat_corr.items():
            print(f"  {feat}: {corr:.3f}")
        
        return corr_matrix
    
    def generate_full_report(self, output_dir='./reports'):
        """
        ç”Ÿæˆå®Œæ•´åˆ†ææŠ¥å‘Š
        """
        import os
        os.makedirs(output_dir, exist_ok=True)
        
        print("\n" + "="*60)
        print("ğŸ“‘ ç”Ÿæˆå®Œæ•´åˆ†ææŠ¥å‘Š")
        print("="*60)
        
        # 1. æ•°æ®æ¦‚è§ˆ
        self.data_overview()
        
        # 2. ä¿å­˜å›¾è¡¨
        self.plot_satisfaction_distribution(save_path=f"{output_dir}/satisfaction_distribution.png")
        market_stats = self.analyze_hunger_phenomenon(save_path=f"{output_dir}/market_cap_analysis.png")
        exp_stats = self.analyze_ab_test(save_path=f"{output_dir}/ab_test_results.png")
        user_stats = self.analyze_user_behavior(save_path=f"{output_dir}/user_behavior.png")
        corr_matrix = self.correlation_analysis()
        
        # 3. ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š
        report_path = f"{output_dir}/eda_report.txt"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("="*60 + "\n")
            f.write("DEEPSEEKé‡‘èå‚åŸŸæ»¡æ„åº¦åˆ†ææŠ¥å‘Š\n")
            f.write("="*60 + "\n\n")
            
            f.write(f"åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"æ ·æœ¬æ•°é‡: {len(self.df):,}\n")
            f.write(f"ç”¨æˆ·æ•°é‡: {self.df['user_id'].nunique():,}\n\n")
            
            f.write("æ ¸å¿ƒå‘ç°:\n")
            f.write("1. 'åƒä¸é¥±'ç°è±¡éªŒè¯: å¤§ç›˜è‚¡æ»¡æ„åº¦ {:.1%}, å°ç›˜è‚¡æ»¡æ„åº¦ {:.1%}\n".format(
                market_stats[market_stats['market_cap_category'] == 'å¤§ç›˜è‚¡ (>1000äº¿)']['æ»¡æ„åº¦'].values[0],
                market_stats[market_stats['market_cap_category'] == 'å°ç›˜è‚¡ (10-100äº¿)']['æ»¡æ„åº¦'].values[0]
            ))
            
            control_sat = exp_stats[exp_stats['experiment_group'] == 'control']['æ»¡æ„åº¦'].values[0]
            combined_sat = exp_stats[exp_stats['experiment_group'] == 'treatment_combined']['æ»¡æ„åº¦'].values[0]
            lift = (combined_sat - control_sat) / control_sat
            f.write(f"2. ABå®éªŒæ•ˆæœ: å®éªŒç»„Cç›¸æ¯”å¯¹ç…§ç»„æå‡ {lift:.1%}\n")
            
            f.write("3. æœ€ä½³ç”¨æˆ·ç¾¤ä½“: {} ç”¨æˆ·æ»¡æ„åº¦æœ€é«˜ ({:.1%})\n".format(
                user_stats['æ»¡æ„åº¦'].idxmax(),
                user_stats['æ»¡æ„åº¦'].max()
            ))
        
        print(f"âœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        print(f"âœ… å›¾è¡¨å·²ä¿å­˜è‡³: {output_dir}")
        
        return {
            'market_stats': market_stats,
            'exp_stats': exp_stats,
            'user_stats': user_stats,
            'corr_matrix': corr_matrix
        }


def main():
    """
    ä¸»å‡½æ•°ï¼šè¿è¡Œå®Œæ•´çš„EDAåˆ†æ
    """
    print("="*60)
    print("ğŸš€ å¼€å§‹ DeepSeek é‡‘èå‚åŸŸæ»¡æ„åº¦ EDA åˆ†æ")
    print("="*60)
    
    # åˆå§‹åŒ–åˆ†æå™¨
    eda = FinancialEDA(n_samples=10000)
    
    # ç”Ÿæˆæ•°æ®
    df = eda.generate_data()
    
    # è¿è¡Œåˆ†æ
    results = eda.generate_full_report(output_dir='./reports')
    
    print("\n" + "="*60)
    print("âœ… EDAåˆ†æå®Œæˆï¼")
    print("="*60)
    
    return results


if __name__ == "__main__":
    results = main()